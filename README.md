fundamental work about DL&DL_compression
### [深度学习之pytorch](https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/tree/master)
##### Chapter 3: 神经网络

- [线性模型与梯度下降(未写)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/linear-regression-gradient-descend.ipynb)

- [Logistic 回归与优化器(logistic_regression.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/logistic-regression/logistic-regression.ipynb)

- [多层神经网络，Sequential 和 Module(nn_sequential_moudle_*.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/nn-sequential-module.ipynb)

- [深层神经网络(nn_sequential_moudle_*.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/deep-nn.ipynb)

- [参数初始化方法(param_initialize.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/param_initialize.ipynb)

- 优化算法(/optimizer)
  
  - [SGD](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/sgd.ipynb)
  - [动量法](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/momentum.ipynb)
  - [Adagrad](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/adagrad.ipynb)
  - [RMSProp](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/rmsprop.ipynb)
  - [Adadelta](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/adadelta.ipynb)
  - [Adam](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/adam.ipynb)

##### Chapter 4: 卷积神经网络

* [PyTorch 中的卷积模块(Basic_conv.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/basic_conv.ipynb)
* [批标准化，batch normalization(Batch_nomalizetion.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/batch-normalization.ipynb)
* [使用重复元素的深度网络，VGG(VGG.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/vgg.ipynb)
* [更加丰富化结构的网络，GoogLeNet(GoogleNet.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/googlenet.ipynb)
* [深度残差网络，ResNet(Resnet.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/resnet.ipynb)
* [稠密连接的卷积网络，DenseNet(Densenet.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/densenet.ipynb)
* 更好的训练卷积网络
  * [数据增强(data-augumentation.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/data-augumentation.ipynb)
  * [正则化(未写)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/regularization.ipynb)
  * [学习率衰减(Lr_decay.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/lr-decay.ipynb)

##### Chapter 5: 循环神经网络

* [循环神经网络模块：LSTM 和 GRU(RNN&LSTM.py)](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/pytorch-rnn.ipynb)
* [使用 RNN 进行图像分类](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/rnn-for-image.ipynb)
* [使用 RNN 进行时间序列分析](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/lstm-time-series.ipynb)
* 自然语言处理的应用：
  * [Word Embedding](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/nlp/word-embedding.ipynb)
  * [N-Gram 模型](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/nlp/n-gram.ipynb)
  * [Seq-LSTM 做词性预测](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/nlp/seq-lstm.ipynb)

##### Chapter 6: 生成对抗网络

* [自动编码器](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter6_GAN/autoencoder.ipynb)
* [变分自动编码器](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter6_GAN/vae.ipynb)
* [生成对抗网络](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter6_GAN/gan.ipynb)
* 深度卷积对抗网络 (DCGANs) 生成人脸

##### Chapter 7: 深度强化学习

* [Q Learning](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter7_RL/q-learning-intro.ipynb)
* [Open AI gym](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter7_RL/open_ai_gym.ipynb)
* [Deep Q-networks](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter7_RL/dqn.ipynb)

##### Chapter 8: PyTorch高级

* [tensorboard 可视化](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter8_PyTorch-Advances/tensorboard.ipynb)
  * [灵活的数据读取介绍](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter8_PyTorch-Advances/data-io.ipynb)
* autograd.function 的介绍
* 数据并行和多 GPU
* 使用 ONNX 转化为 Caffe2 模型
* 如何部署训练好的神经网络
* 打造属于自己的 PyTorch 的使用习惯

#### part2: 深度学习的应用

##### Chapter 9: 计算机视觉

- [Fine-tuning: 通过微调进行迁移学习](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter9_Computer-Vision/fine_tune/)
- kaggle初体验:猫狗大战
- [语义分割: 通过 FCN 实现像素级别的分类](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/tree/master/chapter9_Computer-Vision/segmentation)
- Pixel to Pixel 生成对抗网络
- Neural Transfer: 通过卷积网络实现风格迁移
- Deep Dream: 探索卷积网络眼中的世界

##### Chapter 10: 自然语言处理

- [Char RNN 实现文本生成](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter10_Natural-Language-Process/char_rnn/) 
- Image Caption: 实现图片字幕生成
- seq2seq 实现机器翻译
- cnn + rnn + attention 实现文本识别

### [Awesome Compression](https://github.com/datawhalechina/awesome-compression)

#### [第1章 引言](https://datawhalechina.github.io/awesome-compression/#/ch01/ch01)
  
#### [第2章 CNN基础(未写)](https://datawhalechina.github.io/awesome-compression/#/ch02/ch02)

#### [第3章 模型剪枝(/pruning)](https://datawhalechina.github.io/awesome-compression/#/ch03/ch03)
- 剪枝粒度实践(1.pruning_granularity)
- 剪枝标准实践(2.pruning_criteria)
- 剪枝时机实践(3.pruning_time)
- torch中的剪枝算法实践(4.torch_prune)

#### [第4章 模型量化(/quantization)](https://datawhalechina.github.io/awesome-compression/#/ch04/ch04)
- k-means量化实践(1.kmeans_quantizations)
- 线性量化实践(2.linear_quantization)
- KL量化实践(3.KL_quantization)
- 量化感知训练实践(4.pytorch_QAT)

  
#### [第5章 神经网络架构搜索](https://datawhalechina.github.io/awesome-compression/#/ch05/ch05)
  
#### [第6章 知识蒸馏](https://datawhalechina.github.io/awesome-compression/#/ch06/ch06)
  
#### [第7章 项目实践](https://datawhalechina.github.io/awesome-compression/#/ch07/ch07)
